ğŸ“© Spam Classifier with Explanation (FastAPI + Streamlit + LLM)
An end-to-end Spam Detection system that not only classifies messages as Spam / Not Spam, but also explains the reasoning behind the prediction using a Large Language Model.
________________________________________
ğŸš€ Live Demo
ğŸ”— Streamlit App
ğŸ‘‰ https://spam-classifier-with-explanation.streamlit.app/
ğŸ”— FastAPI Backend
ğŸ‘‰ https://spam-classifier-api-uiiy.onrender.com
________________________________________
ğŸ§  Project Overview
This project combines:
â€¢	A traditional Machine Learning classifier for accurate spam detection
â€¢	A Large Language Model (LLM) to provide human-friendly explanations and advice
Why this approach?
â€¢	ML models are fast and reliable for classification
â€¢	LLMs make predictions explainable and user-friendly
________________________________________
ğŸ§ª Spam Classification Model
ğŸ“Œ Model Used
Multinomial Naive Bayes
This model is trained on processed SMS/Email text using TF-IDF vectorization, making it highly effective for text classification tasks.
ğŸ“Š Model Performance
Metric	Score
Accuracy	0.9822
Precision	0.99
Recall	0.8534
F1-Score	0.9167
âœ” High precision ensures very few false spam alerts
âœ” Strong recall ensures most spam messages are caught
________________________________________
ğŸ¤– Large Language Model (LLM) for Explanation
ğŸ“Œ Model Used
LLaMA-3.1-8B-Instant
The LLM is used after classification to:
â€¢	Explain why a message is spam or not
â€¢	Identify the type of spam (phishing, promotion, scam, etc.)
â€¢	Provide one practical safety suggestion
ğŸ§  Why LLaMA-3.1-8B-Instant?
â€¢	Excellent reasoning and instruction following
â€¢	Fast inference for real-time APIs
â€¢	Generates clear, concise, and contextual explanations
â€¢	Ideal for Explainable AI (XAI) use cases
________________________________________
ğŸ”„ System Workflow
1.	User enters a message
2.	Text is preprocessed (tokenization, stopwords removal, stemming)
3.	Multinomial Naive Bayes predicts â†’ Spam / Not Spam
4.	Prediction + message are sent to LLaMA-3.1-8B-Instant
5.	User receives:
o	Classification result
o	Explanation
o	One safety recommendation
________________________________________
ğŸ§© API Endpoints
1ï¸âƒ£ Spam Prediction
POST /spam/predict
Request
{
  "text": "Congratulations! You have won a free prize"
}
Response
{
  "text": "Congratulations! You have won a free prize",
  "prediction": "Spam"
}
________________________________________
2ï¸âƒ£ Spam Explanation
POST /spam/explain
Input
â€¢	User message
â€¢	Model prediction
Output
â€¢	Type of spam
â€¢	Reason for classification
â€¢	One helpful advice
________________________________________
ğŸ–¥ï¸ Streamlit App Features
â€¢	Clean UI for user input
â€¢	Displays:
o	ğŸ”¹ Spam / Not Spam prediction
o	ğŸ”¹ LLM-generated explanation
â€¢	Uses live FastAPI backend
â€¢	Beginner-friendly and responsive
________________________________________
ğŸ›  Tech Stack
â€¢	Backend: FastAPI
â€¢	Frontend: Streamlit
â€¢	ML Model: Multinomial Naive Bayes
â€¢	Vectorization: TF-IDF
â€¢	LLM: LLaMA-3.1-8B-Instant
â€¢	NLP: NLTK
â€¢	Deployment:
o	API â†’ Render
o	App â†’ Streamlit Cloud
________________________________________
ğŸ“Œ Key Highlights
âœ” High-accuracy spam detection
âœ” Explainable AI output
âœ” Real-time API + UI
âœ” Production-ready architecture
âœ” Clear separation of ML and LLM layers
________________________________________
ğŸ“¬ Future Improvements
â€¢	Add confidence scores
â€¢	Multi-language spam detection
â€¢	User feedback loop
â€¢	Model retraining pipeline
________________________________________
ğŸ‘¤ Author
Alekhya Chatterjee
If you found this useful, feel free to â­ the repository!


